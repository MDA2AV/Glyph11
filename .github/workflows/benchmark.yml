name: Benchmark

on:
  workflow_dispatch:
  pull_request:
    branches: [ main ]

jobs:

  parsers:

    name: Parser Benchmarks

    if: github.event_name == 'pull_request'

    runs-on: ubuntu-latest

    permissions:
      pull-requests: write

    steps:

    - name: Checkout
      uses: actions/checkout@v4

    - name: Download .NET SDK
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: 10.0

    - name: Run parser benchmarks
      run: dotnet run -c Release -- --filter '*FlexibleParserBenchmark*' '*HardenedParserBenchmark*'
      working-directory: src/Benchmarks

    - name: Upload results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: parser-benchmark-results
        path: src/Benchmarks/BenchmarkDotNet.Artifacts/results/

    - name: Combine benchmark JSON results
      run: |
        jq -s '{ Benchmarks: [ .[].Benchmarks[] ] }' \
          src/Benchmarks/BenchmarkDotNet.Artifacts/results/*-report-full-compressed.json \
          > combined-benchmarks.json

    - name: Add allocation metrics to combined results
      run: |
        python3 -c "
        import json, glob
        files = glob.glob('src/Benchmarks/BenchmarkDotNet.Artifacts/results/*-report-full-compressed.json')
        alloc_entries = []
        for f in files:
            with open(f) as fh:
                data = json.load(fh)
            for b in data.get('Benchmarks', []):
                alloc = b.get('Memory', {}).get('BytesAllocatedPerOperation', 0)
                if alloc and alloc > 0:
                    alloc_entries.append({
                        'FullName': b['FullName'] + '.Allocated',
                        'Statistics': {'Mean': float(alloc), 'StandardDeviation': 0.0},
                        'Namespace': b.get('Namespace', ''),
                        'Type': b.get('Type', ''),
                        'Method': b.get('Method', '') + '_Allocated'
                    })
        with open('combined-benchmarks.json') as fh:
            combined = json.load(fh)
        combined['Benchmarks'].extend(alloc_entries)
        with open('combined-benchmarks.json', 'w') as fh:
            json.dump(combined, fh)
        "

    - name: Compare against baseline
      uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
      with:
        tool: 'benchmarkdotnet'
        output-file-path: combined-benchmarks.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '115%'
        fail-on-alert: true
        comment-on-alert: true
        comment-always: true
        summary-always: true

  full:

    name: Full Benchmarks

    if: github.event_name == 'workflow_dispatch'

    runs-on: ubuntu-latest

    permissions:
      contents: write

    steps:

    - name: Checkout
      uses: actions/checkout@v4

    - name: Download .NET SDK
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: 10.0

    - name: Run all benchmarks
      run: dotnet run -c Release -- --filter '*'
      working-directory: src/Benchmarks

    - name: Upload results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: full-benchmark-results
        path: src/Benchmarks/BenchmarkDotNet.Artifacts/results/

    - name: Combine benchmark JSON results
      run: |
        jq -s '{ Benchmarks: [ .[].Benchmarks[] ] }' \
          src/Benchmarks/BenchmarkDotNet.Artifacts/results/*-report-full-compressed.json \
          > combined-benchmarks.json

    - name: Add allocation metrics to combined results
      run: |
        python3 -c "
        import json, glob
        files = glob.glob('src/Benchmarks/BenchmarkDotNet.Artifacts/results/*-report-full-compressed.json')
        alloc_entries = []
        for f in files:
            with open(f) as fh:
                data = json.load(fh)
            for b in data.get('Benchmarks', []):
                alloc = b.get('Memory', {}).get('BytesAllocatedPerOperation', 0)
                if alloc and alloc > 0:
                    alloc_entries.append({
                        'FullName': b['FullName'] + '.Allocated',
                        'Statistics': {'Mean': float(alloc), 'StandardDeviation': 0.0},
                        'Namespace': b.get('Namespace', ''),
                        'Type': b.get('Type', ''),
                        'Method': b.get('Method', '') + '_Allocated'
                    })
        with open('combined-benchmarks.json') as fh:
            combined = json.load(fh)
        combined['Benchmarks'].extend(alloc_entries)
        with open('combined-benchmarks.json', 'w') as fh:
            json.dump(combined, fh)
        "

    - name: Compare and update baseline
      uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1
      with:
        tool: 'benchmarkdotnet'
        output-file-path: combined-benchmarks.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        auto-push: ${{ github.ref == 'refs/heads/main' }}
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: benchmarks
        alert-threshold: '115%'
        fail-on-alert: true
        comment-on-alert: true
        summary-always: true

    - name: Rebuild docs site
      if: github.ref == 'refs/heads/main'
      run: gh workflow run "Deploy Docs to GitHub Pages"
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
